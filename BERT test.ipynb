{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Bbr5Ts6J8pUG"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "encoder_URL = \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-12-h-768-a-12/versions/2\"\n",
        "preprocessor = 'https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3'\n",
        "text_preprocessor = hub.KerasLayer(preprocessor) # First layer of the NN"
      ]
    },
    {
      "source": [
        "testing_sent = ['hello world', 'wow the world is just beautiful']\n",
        "processed_text = text_preprocessor(testing_sent)\n",
        "processed_text.keys()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwmpq8PF9FnW",
        "outputId": "c0d07f16-1d91-4f59-a537-d721d01ec107"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_mask', 'input_type_ids', 'input_word_ids'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_text['input_mask']\n",
        "\n",
        "# Format of 'input mask' is SLC your_string SEP\n",
        "# The input_mask just captures the given words and masks the length of the words that exist\n",
        "# Max sentence length can be 126"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYu54_oU80YI",
        "outputId": "ff1b48e5-f39c-4b3c-cbf4-7e68de90f049"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_text['input_word_ids']\n",
        "# This is the dictionary value for each of the words passed in. You can see the dictionary value for 'world' is 2088\n",
        "# preprocesses text by tokenizing and has it ready in numerical form"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_dKjeOcAASF",
        "outputId": "3a0fbd9f-0272-4e28-b2b9-9b904bb6d826"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
              "array([[  101,  7592,  2088,   102,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0],\n",
              "       [  101, 10166,  1996,  2088,  2003,  2074,  3376,   102,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert = hub.KerasLayer(encoder_URL)\n",
        "bert_model_with_preprocessed = bert(processed_text)\n",
        "bert_model_with_preprocessed.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sLSoVw2Aqx_",
        "outputId": "25c5dc76-c68a-4334-a169-a7adef5c9665"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['encoder_outputs', 'sequence_output', 'default', 'pooled_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_with_preprocessed['pooled_output']\n",
        "# 'pooled_output' this will produce the embeddings or vector for each sentence.\n",
        "# The embedding represents the meaning behind the sentence using 768 features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iBviIdECKCH",
        "outputId": "29db9302-3df2-4a96-8a1c-e27b11fdb5fe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
              "array([[ 0.46143854,  0.16888136,  0.9770442 , ..., -0.9247109 ,\n",
              "         0.32970682,  0.99962413],\n",
              "       [-0.18566011, -0.4565327 ,  0.991772  , ..., -0.9822351 ,\n",
              "         0.31540486,  0.9982238 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_with_preprocessed['sequence_output']\n",
        "# This does it for all the words in each sentence.\n",
        "# You are able to represent those words with numbers that take in account of the meaning behind the words.\n",
        "# Shape Analysis: (2, 128, 768)\n",
        "#.   2 represents the sentences\n",
        "#    Then each of those sentences the model is going through each of the words that could max be 128\n",
        "#.   Finally in each word it produces 768 feature values to represent that word."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wBcLbRdC_dT",
        "outputId": "ebf7ddb6-252b-4278-fd65-5ad744094c5e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
              "array([[[ 1.38968721e-01,  3.92372489e-01,  2.20877841e-01, ...,\n",
              "         -7.50904530e-02, -1.59458995e-01, -3.02657783e-01],\n",
              "        [-4.81071249e-02,  7.19874620e-01,  4.84751046e-01, ...,\n",
              "          1.99355274e-01,  1.33780956e-01, -1.23020828e-01],\n",
              "        [ 6.01866782e-01,  9.01288390e-02,  1.09629035e-01, ...,\n",
              "          5.26783057e-04,  2.54782945e-01, -1.13370605e-01],\n",
              "        ...,\n",
              "        [ 2.21234679e-01,  2.39344776e-01,  3.30342650e-01, ...,\n",
              "         -2.52432913e-01, -1.81307316e-01, -1.54258817e-01],\n",
              "        [ 1.02187499e-01,  4.07734334e-01,  2.37250060e-01, ...,\n",
              "         -1.88559338e-01, -1.58265829e-01, -1.90354176e-02],\n",
              "        [ 4.62288797e-01,  7.18413115e-01, -1.38182297e-01, ...,\n",
              "         -9.43192188e-03,  1.22147448e-01, -4.43378448e-01]],\n",
              "\n",
              "       [[-1.13890581e-02,  3.06114499e-02,  6.04448676e-01, ...,\n",
              "         -1.62474178e-02,  3.43062103e-01, -4.55624461e-01],\n",
              "        [ 8.25801611e-01, -1.35105819e-01,  5.15725791e-01, ...,\n",
              "         -7.24700093e-02,  4.04624641e-01, -5.06983697e-03],\n",
              "        [ 3.24169278e-01,  1.09208100e-01,  5.15560746e-01, ...,\n",
              "          7.36624748e-02,  1.72208220e-01,  4.78068084e-01],\n",
              "        ...,\n",
              "        [ 4.31810856e-01, -3.03584039e-02,  1.07802972e-02, ...,\n",
              "         -9.64947939e-02, -2.85091877e-01,  3.91663611e-01],\n",
              "        [ 1.99784517e-01,  5.95755517e-01,  4.86944675e-01, ...,\n",
              "         -2.00083703e-01,  1.48158938e-01, -1.76886231e-01],\n",
              "        [ 2.14428216e-01,  1.77538991e-01,  3.88223976e-01, ...,\n",
              "         -3.93772811e-01,  1.05652004e-01,  4.02750134e-01]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_with_preprocessed['encoder_outputs'][-1] == bert_model_with_preprocessed['sequence_output']\n",
        "# same as the sequence output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXo1BgewDo4n",
        "outputId": "e37935a7-bd15-4faf-af5a-cec943bdaddc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128, 768), dtype=bool, numpy=\n",
              "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]]])>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u97Y_8QWFf1H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}